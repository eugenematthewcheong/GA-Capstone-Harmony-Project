{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b85e086",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone Project: Harmony\n",
    "## 1.1 Web scraping - Lian Seng Hin\n",
    "> Authors: Eugene Matthew Cheong\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6353a40a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This project is designed to assist interior designers by optimizing the selection of interior design products. It compiles a detailed catalogue of items such as tiles, laminates, and paints, and employs cosine similarity calculations to find and suggest products that closely match desired colors. This feature enhances the ability to match color palettes with precision, catering to client preferences and design requirements.\n",
    "\n",
    "Additionally, the system includes an image matching feature, which allows designers to upload images provided by clients or photos of spaces to be redesigned. It automatically identifies and suggests corresponding products from the catalogue. This capability ensures that designers can efficiently align client expectations with the available inventory, thereby streamlining the design process.\n",
    "\n",
    "---\n",
    "\n",
    "## Persona\n",
    "George has spent eight years designing beautiful homes, adjusting to different client preferences. Despite his experience, he often finds it difficult to start new projects because of the vast array of products and colours available. He also struggles to understand what clients want from their text messages alone. George needs a way to simplify the beginning of his design projects and better grasp client needs.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Statement\n",
    "How can we help interior designers recommend designs more efficiently?\n",
    "\n",
    "---\n",
    "\n",
    "## Approach\n",
    "By using arecommendation system, it will be tailored to support interior designers by suggesting products based on an initial color or product choice. The system begins by analyzing the color characteristics of the chosen item. Utilizing cosine similarity calculations, it identifies products within our comprehensive catalogue that have similar color properties.\n",
    "\n",
    "Once a base color or product is selected, the system generates a color palette that harmonizes with the initial choice. This palette serves as a guide for interior designers, enabling them to recommend a range of products that not only match but also complement the core color scheme.\n",
    "\n",
    "This approach ensures a cohesive aesthetic across the design project, allowing designers to confidently match products with the overall style and color preferences of their clients. The documentation provided here explains the technical and practical aspects of this approach, offering a clear pathway for designers to leverage the system's capabilities effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afde4af",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cfa7b2",
   "metadata": {},
   "source": [
    "## Table of Contents ##\n",
    "\n",
    "#### 1. Web Scraping\n",
    "\n",
    "- [1.1 Scraping Lian Seng Hin Website](1.1_web_scraping_liansenghin.ipynb)\n",
    "- [1.2 Scraping Hafary Website](1.2_web_scraping_hafary.ipynb)\n",
    "- [1.3 Scraping Lamitak Website](1.3_web_scraping_lamitak.ipynb)\n",
    "- [1.4 Scraping Nippon Website](1.4_web_scraping_nippon.ipynb)\n",
    "- [1.5 Consolidate All Product Database](1.5_consolidate_product_database.ipynb)\n",
    "\n",
    "#### 2. Preprocessing\n",
    "\n",
    "- [2.1 Processing Canva Palettes](2.1_processing_canva_palette.ipynb)\n",
    "\n",
    "#### 3. Modelling\n",
    "\n",
    "- [3.1 Matching Input Photo to Products](3.1_matching_input_photo_to_products.ipynb)\n",
    "- [3.2 Recommending Canva Palette to Products](3.2_recommending_canva_palette_to_product.ipynb)\n",
    "- [3.3 Recommending Colours and Colour Palettes with Llama3](3.3_recommending_colours_and_colour_palettes_with_llama3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8283d11b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15267fb4",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c994bbbb-74ef-49f6-9823-282217604394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35bd414",
   "metadata": {},
   "source": [
    "# Website to scrape\n",
    "- https://liansenghin.com.sg/product-category/tiles/\n",
    "- https://liansenghin.com.sg/product-category/uncategorized/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2137fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Links to scrape\n",
    "links_list = [\"https://liansenghin.com.sg/product-category/tiles/\",\n",
    "              \"https://liansenghin.com.sg/product-category/uncategorized/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726bb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting variable for location of the images\n",
    "data_img_folder = \"../datasets/images\"\n",
    "liansenghin_img_folder =  os.path.join(data_img_folder,\"liansenghin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16587351",
   "metadata": {},
   "source": [
    "# Scraping for Lian Seng Hin tile products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d2abb8",
   "metadata": {},
   "source": [
    "### Function to scrape information required per Lian Seng Hin page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9caa47-8313-4830-99b0-cf805fac493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape images and labels from a single page\n",
    "def scrape_page(url,input_folder):\n",
    "\n",
    "    # Create a directory to store images\n",
    "    os.makedirs(input_folder, exist_ok=True)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {url}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find image containers within the specified class\n",
    "    image_containers = soup.find_all('div', class_='modus-column-custom')\n",
    "\n",
    "    # Extract image URLs and labels\n",
    "    for container in image_containers:\n",
    "        label_tag = container.find('div', class_=\"ct-product-right\")\n",
    "        label = label_tag.find('a')['href'].split(\"/\")[-2]\n",
    "\n",
    "        image_tags = container.find_all('a')\n",
    "        image_tags = container.find_all('img')\n",
    "        for image_tag in image_tags:\n",
    "            image_url = image_tag['src']\n",
    "            \n",
    "            #Download image and save with label\n",
    "\n",
    "            download_image(image_url, label, input_folder) # Uncomment this if you would like to download the images.\n",
    "            print(f\"Image Label Found: {label}\")\n",
    "            print(f\"Image URL Found: {image_url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b178d",
   "metadata": {},
   "source": [
    "### Function to download images with given URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2209ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download image and save with label\n",
    "def download_image(url, label, input_folder):\n",
    "    try:\n",
    "        image_data = requests.get(url).content\n",
    "        filename = f\"{label}.jpg\"\n",
    "        image_filepath = os.path.join(input_folder,filename)\n",
    "        with open(image_filepath, 'wb') as f:\n",
    "            f.write(image_data)\n",
    "        print(f\"Image saved: {image_filepath}\")\n",
    "    except:\n",
    "        print(f'Unable to save image: {url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7164851",
   "metadata": {},
   "source": [
    "### Function to scrape Lian Seng Hin Tile pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1a945-61dc-4cf5-b7b7-61604c3f77a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to iterate through pages and scrape\n",
    "def liansenghin_scrape(base_url):\n",
    "    page_number = 1\n",
    "    # Iterate through pages\n",
    "    while True:\n",
    "        page_url = f\"{base_url}page/{page_number}/\"\n",
    "        response = requests.get(page_url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"No more pages. Exiting.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Scraping page {page_number}...\")\n",
    "        scrape_page(page_url,liansenghin_img_folder)\n",
    "        page_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bad56d-05c3-47ef-98a8-c31d8f366eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for link in links_list:\n",
    "  print(f\"Scraping current link {link}\")\n",
    "  liansenghin_scrape(link)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "runtime = end_time - start_time\n",
    "print(\"Scraping Runtime:\", runtime, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec49eb5",
   "metadata": {},
   "source": [
    "# Gathering the details of the products in their sub-pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9989831a",
   "metadata": {},
   "source": [
    "### Gathering Category tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb426ef4",
   "metadata": {},
   "source": [
    "Getting the list of image file names in the liansenghin_img_folder to get the product URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e008a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "listdir = os.listdir(liansenghin_img_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36638e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb6f22",
   "metadata": {},
   "source": [
    "### Base URL that the website use to store their tile products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_product_url = \"https://liansenghin.com.sg/product/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655dfb39",
   "metadata": {},
   "source": [
    "### To list out the product URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b094be8",
   "metadata": {},
   "source": [
    "Taking the product name from the file and adding to the base url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16509a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = []\n",
    "\n",
    "for imagefile in listdir:\n",
    "  imagename = os.path.splitext(imagefile)[0]\n",
    "  product_url = f\"{base_product_url}{imagename}/\"\n",
    "  current_product = {\"Model Name\" : imagename, \n",
    "                     \"Product URL\" : product_url, \n",
    "                     \"Filename\" : imagefile, \n",
    "                     \"Company\" : \"Lian Seng Hin\",\n",
    "                    \"Type\" : \"Tiles\",\n",
    "                     \"Application\" : \"Floor\" }\n",
    "  product_list.append(current_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bce9aed",
   "metadata": {},
   "source": [
    "Converting to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = pd.DataFrame(product_list)\n",
    "product_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e681fd",
   "metadata": {},
   "source": [
    "### This function populates the \"Category tags\" scraped from each product site with tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179dbe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page_categories(row):\n",
    "    print(\"Processing row:\", row.name)\n",
    "    url = row['Product URL']\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {url}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find image containers within the specified class\n",
    "    product_meta_details = soup.find_all('span', class_='posted_in')\n",
    "\n",
    "    # Extract categories from each span element\n",
    "    categories = []\n",
    "    for details in product_meta_details:\n",
    "        # Find all 'a' tags within the span\n",
    "        category_links = details.find_all('a')\n",
    "        for link in category_links:\n",
    "            categories.append(link.get_text())\n",
    "\n",
    "    categories_string = ', '.join(categories)\n",
    "    return(categories_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df['Category Tags'] = product_df.apply(scrape_page_categories, axis=1)\n",
    "\n",
    "# Remove rows where the function returned None\n",
    "product_df = product_df.dropna(subset=['Category Tags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ec2696",
   "metadata": {},
   "source": [
    "### This function populates the \"Origin Country\" scraped from each product site with where it was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd34263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page_country(row):\n",
    "    print(\"Processing row:\", row.name)\n",
    "    url = row['Product URL']\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {url}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find image containers within the specified class\n",
    "    product_attributes_country = soup.find_all('tr', class_=\"woocommerce-product-attributes-item woocommerce-product-attributes-item--attribute_pa_country\")\n",
    "\n",
    "    # Extract categories from each span element\n",
    "    for details in product_attributes_country:\n",
    "        # Find all 'a' tags within the span\n",
    "        country = details.find_all('p')[0].text.strip()\n",
    "\n",
    "    return(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b949f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "product_df['Origin Country'] = product_df.apply(scrape_page_country, axis=1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "runtime = end_time - start_time\n",
    "print(\"Scraping Runtime:\", runtime, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bff59d2",
   "metadata": {},
   "source": [
    "### This function populates the \"Dimension\" scraped from each product site with the dimension of the tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7663b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page_dimension(row):\n",
    "    print(\"Processing row:\", row.name)\n",
    "    url = row['Product URL']\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {url}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find image containers within the specified class\n",
    "    product_attributes_dimension = soup.find_all('tr', class_=\"woocommerce-product-attributes-item woocommerce-product-attributes-item--attribute_pa_size\")\n",
    "\n",
    "    # Extract categories from each span element\n",
    "    for details in product_attributes_dimension:\n",
    "        # Find all 'a' tags within the span\n",
    "        dimension = details.find_all('p')[0].text.strip()\n",
    "\n",
    "    return(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "product_df['Dimension (cm)'] = product_df.apply(scrape_page_dimension, axis=1)\n",
    "\n",
    "runtime = end_time - start_time\n",
    "print(\"Scraping Runtime:\", runtime, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07c3fe",
   "metadata": {},
   "source": [
    "Removing the \" CM\" in the dimensions so that we can split the width and height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12601b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df['Dimension (cm)'] = product_df['Dimension (cm)'].str.replace(\"CM\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd230f",
   "metadata": {},
   "source": [
    "Changes all \"X\" to \"x\". To easily remove all of the \"x\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02395ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df['Dimension (cm)'] = product_df['Dimension (cm)'].str.replace(\"X\", \"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342b4fa",
   "metadata": {},
   "source": [
    "Split the dimension into height and weight column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507047b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df[['Width (cm)', 'Height (cm)']] = product_df['Dimension (cm)'].str.split(\" x \", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d5b0b0",
   "metadata": {},
   "source": [
    "No longer need the 'Dimension (cm)' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb42ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.drop(columns='Dimension (cm)', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5de9aa",
   "metadata": {},
   "source": [
    "Fix back \"HEXAGON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df['Width (cm)'] = product_df['Width (cm)'].str.replace(\"HExAGON\", \"HEXAGON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63e32d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac9089",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc11efd",
   "metadata": {},
   "source": [
    "There are some values that are not numerical. Will attend to it later on to see if the information is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4566b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df['Width (cm)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df['Height (cm)'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a773530",
   "metadata": {},
   "source": [
    "# Export Dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a07837",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_dataset_path = \"../datasets/archive_dataset/\"\n",
    "file_path = '../datasets/liansenghin_df.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266fdac",
   "metadata": {},
   "source": [
    "Archives the old csv and updates with the current list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6f2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(archive_dataset_path):\n",
    "    os.makedirs(archive_dataset_path)  # Create the archive folder if it doesn't exist\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.isfile(file_path):\n",
    "    # Move the file to the archive folder\n",
    "    shutil.move(file_path, os.path.join(archive_dataset_path, f\"liansenghin_df_archived_{pd.Timestamp.now().strftime('%Y%m%d%H%M%S')}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954f7c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.to_csv(\"../datasets/liansenghin_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608d2e1",
   "metadata": {},
   "source": [
    "I noticed after scraping, there are some images that are not correct and showing the tile image. It shows a room instead. So I will update the images later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210c540",
   "metadata": {},
   "source": [
    "# Find missing files and update to the correct image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_image_list = []\n",
    "\n",
    "for i in list(product_df['Filename']):\n",
    "  full_image_filepath = os.path.join(liansenghin_img_folder,i)\n",
    "  if os.path.exists(full_image_filepath):\n",
    "    missing_image_list.append(os.path.join(liansenghin_img_folder,i))\n",
    "  else:\n",
    "    print(f\"Error finding image path: {full_image_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a3106",
   "metadata": {},
   "source": [
    "# Moving old product image to archive when it is no longer in the CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a76413",
   "metadata": {},
   "source": [
    "When there are new updates to the catalogue, it will archive the images so that it will not be included in the recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_img_path = os.path.join(liansenghin_img_folder,\"archived\")\n",
    "if not os.path.exists(archive_img_path):\n",
    "    os.makedirs(archive_img_path)  # Create the archive folder if it doesn't exist\n",
    "\n",
    "# Iterate over all files in the image folder\n",
    "for image in listdir:\n",
    "    if os.path.isfile(image):\n",
    "        # Extract the name or identifier from the image filename\n",
    "        image_name = os.path.basename(image)  # Adjust this according to your filename structure\n",
    "\n",
    "        # Check if this image_name exists in the DataFrame\n",
    "        if not any(product_df['Filename'].astype(str).str.contains(image_name)):\n",
    "            # Move the file to the archive folder\n",
    "            try:\n",
    "                shutil.move(os.path.join(liansenghin_img_folder, image), os.path.join(archive_img_path, image))\n",
    "                print(f'Image moved to archived: {os.path.join(liansenghin_img_folder, image)}')\n",
    "            except:\n",
    "                print(f'Error: Image not found: {os.path.join(liansenghin_img_folder, image)}')\n",
    "\n",
    "            print(image_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d24ee7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da32b9c",
   "metadata": {},
   "source": [
    "### Next Notebook: [1.2 Scraping Hafary Website](1.2_web_scraping_hafary.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
