{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff941625",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone Project: Harmony\n",
    "## 1.4 Web scraping - Nippon\n",
    "> Authors: Eugene Matthew Cheong\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf63aea",
   "metadata": {},
   "source": [
    "## Table of Contents ##\n",
    "\n",
    "#### 1. Web Scraping\n",
    "\n",
    "- [1.1 Scraping Lian Seng Hin Website](1.1_web_scraping_liansenghin.ipynb)\n",
    "- [1.2 Scraping Hafary Website](1.2_web_scraping_hafary.ipynb)\n",
    "- [1.3 Scraping Lamitak Website](1.3_web_scraping_lamitak.ipynb)\n",
    "- [1.4 Scraping Nippon Website](1.4_web_scraping_nippon.ipynb)\n",
    "- [1.5 Consolidate All Product Database](1.5_consolidate_product_database.ipynb)\n",
    "\n",
    "#### 2. Preprocessing\n",
    "\n",
    "- [2.1 Processing Canva Palettes](2.1_processing_canva_palette.ipynb)\n",
    "\n",
    "#### 3. Modelling\n",
    "\n",
    "- [3.1 Matching Input Photo to Products](3.1_matching_input_photo_to_products.ipynb)\n",
    "- [3.2 Recommending Canva Palette to Products](3.2_recommending_canva_palette_to_product.ipynb)\n",
    "- [3.3 Recommending Colours and Colour Palettes with Llama3](3.3_recommending_colours_and_colour_palettes_with_llama3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e713cb8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcda277",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c994bbbb-74ef-49f6-9823-282217604394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd14503",
   "metadata": {},
   "source": [
    "# Website to scrape\n",
    "- https://nipponpaint.com.sg/colours/find-your-colour/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512e214-26d2-4902-bf8b-7ca12ec1110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_img_folder = \"../datasets/images\"\n",
    "nippon_img_folder =  os.path.join(data_img_folder,\"nippon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3a14f1",
   "metadata": {},
   "source": [
    "# Gathering the \"Colour Family\" links as they are considered \"pages\" in this website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_web_color_page = 'https://nipponpaint.com.sg/colours/find-your-colour/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86212fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(main_web_color_page)\n",
    "if response.status_code != 200:\n",
    "    print(f\"Failed to fetch {main_web_color_page}\")\n",
    "else:\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "  # Find colour containers within the specified class\n",
    "  colour_family_container = soup.find('div', class_=\"colour-family\")\n",
    "  colour_link_found = colour_family_container.find_all('a')\n",
    "  colour_links_list = []\n",
    "  for colour in colour_link_found:\n",
    "     colour_links_list.append(colour['href'])\n",
    "     print(f'Colour Link Found: {colour[\"href\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4792f3ed",
   "metadata": {},
   "source": [
    "## Function to scrape information required per Nippon Colour Family page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9caa47-8313-4830-99b0-cf805fac493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape images and labels from a single page\n",
    "def scrape_page(url,input_folder):\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {url}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find image containers within the specified class\n",
    "    item_containers = soup.find('div', class_=\"colours-item-box\")\n",
    "\n",
    "    product_list = []\n",
    "    \n",
    "    image_containers = item_containers.find_all('div', class_='col-6 col-md-3')\n",
    "    for image in image_containers:\n",
    "        alL_colour_info = image.find_all('h5', class_='card-title')\n",
    "        for colour_info in alL_colour_info:\n",
    "            paint_label = colour_info.text.strip()\n",
    "            paint_url = colour_info.find('a')['href']\n",
    "            \n",
    "            print(f\"Paint Label Found: {colour_info.text.strip()}\")\n",
    "            print(f\"Paint URL Found: {colour_info.find('a')['href']}\")\n",
    "                \n",
    "        \n",
    "            imagedict = {\"Model Name\": f\"{colour_info.text.strip()}\",\n",
    "                        \"Product URL\": colour_info.find('a')['href'],\n",
    "                        \"Type\": \"Paint\",\n",
    "                        \"Application\": \"Wall\",\n",
    "                        \"Company\": \"Nippon\",\n",
    "                        \"Origin Country\": \"None\",\n",
    "                        \"Category Tags\": \"\"\n",
    "                        }\n",
    "\n",
    "            product_list.append(imagedict)\n",
    "\n",
    "    return product_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d706e1",
   "metadata": {},
   "source": [
    "## Function to download images with given URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c626ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download image and save with label\n",
    "def download_image(url, label, input_folder):\n",
    "    image_data = requests.get(url).content\n",
    "    filename = f\"{label}.jpg\"\n",
    "    image_filepath = os.path.join(input_folder,filename)\n",
    "    with open(image_filepath, 'wb') as f:\n",
    "        f.write(image_data)\n",
    "    print(f\"Image saved: {image_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33efa9eb",
   "metadata": {},
   "source": [
    "# Launch scraping for Nippon products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bad56d-05c3-47ef-98a8-c31d8f366eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launch scraping for lian seng hin tile products\n",
    "start_time = time.time()\n",
    "\n",
    "all_product_list = []\n",
    "\n",
    "for link in colour_links_list:\n",
    "  product_list_page = scrape_page(link,nippon_img_folder)\n",
    "  all_product_list += product_list_page\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "runtime = end_time - start_time\n",
    "print(\"Scraping Runtime:\", runtime, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a73b2",
   "metadata": {},
   "source": [
    "Converting to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bbfe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = pd.DataFrame(all_product_list)\n",
    "product_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007b7b87",
   "metadata": {},
   "source": [
    "# Populate Paint details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc20443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hex_to_rgb(input_hex):\n",
    "  h = input_hex.lstrip('#')\n",
    "  return tuple(int(h[i:i+2], 16) for i in (0, 2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a7af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_paint_details(row):\n",
    "   print(\"Processing row:\", row.name)\n",
    "   product_url = row['Product URL']\n",
    "   print(product_url)\n",
    "   try:\n",
    "      response = requests.get(product_url)\n",
    "      if response.status_code != 200:\n",
    "         print(f\"Failed to fetch {product_url}\")\n",
    "         return\n",
    "\n",
    "      soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "      # Find image containers within the specified class\n",
    "\n",
    "\n",
    "      info_containers = soup.find('div', class_=\"row my-4\")\n",
    "      #print(info_containers)\n",
    "      color_code = info_containers.find('div', class_=\"color-box\")['style'].replace(\"background-color: \",\"\").replace(\";\",\"\")\n",
    "      color_code_rgb = convert_hex_to_rgb(color_code)\n",
    "\n",
    "      model_number = info_containers.find('div', class_=\"col-lg-12 col-12\").find('h2').text.strip()\n",
    "\n",
    "      print(model_number)\n",
    "      print(f\"Paint Color Code Found: {color_code}\")\n",
    "      print(f\"Paint Color RGB Found: {color_code_rgb}\")\n",
    "      print(f\"Paint Model Number Found: {model_number}\")\n",
    "      row['Color Code'] = color_code\n",
    "      row['Color R'] = color_code_rgb[0]\n",
    "      row['Color G'] = color_code_rgb[1]\n",
    "      row['Color B'] = color_code_rgb[2]\n",
    "      row['Model Number'] = model_number\n",
    "   except:\n",
    "      print(f\"Unable to process row: {product_url}. Please try again.\")\n",
    "\n",
    "   return row\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90aeef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "product_df =  product_df.apply(populate_paint_details, axis=1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "runtime = end_time - start_time\n",
    "print(\"Scraping Runtime:\", runtime, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d601366",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef73ee",
   "metadata": {},
   "source": [
    "# Generate color PNG for model and updating dataframe with product filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ea63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_color_images(row):\n",
    "  print(\"Processing row:\", row.name)\n",
    "  # Ensure the folder exists\n",
    "  if not os.path.exists(nippon_img_folder):\n",
    "      os.makedirs(nippon_img_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "  height, width, channel = 300, 300, 3\n",
    "\n",
    "  #Define Red,Green,Blue Color -for each- 0 to 255\n",
    "  red, green, blue = row['Color R'], row['Color G'], row['Color B']\n",
    "\n",
    "  #Generate RGB Numpy Array \n",
    "  image_data = np.full((height, width, channel), [red, green, blue], dtype=('uint8'))\n",
    "\n",
    "  plt.imshow(image_data)\n",
    "  plt.axis('off')\n",
    "\n",
    "  # Save the figure\n",
    "  output_img_filename = f\"{nippon_img_folder}/{row['Model Number']}.png\"\n",
    "  print(f\"Saving image: {output_img_filename}\")\n",
    "  plt.savefig(output_img_filename, bbox_inches='tight', pad_inches=0)\n",
    "  plt.close()\n",
    "  row['Filename'] = os.path.basename(output_img_filename)\n",
    "  print(row)\n",
    "\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd8ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#save_color_images(product_df, nippon_img_folder)\n",
    "product_df = product_df.apply(save_color_images, axis=1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "runtime = end_time - start_time\n",
    "print(\"Generating Color PNG:\", runtime, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcc987",
   "metadata": {},
   "source": [
    "# Export Dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_dataset_path = \"../datasets/archive_dataset/\"\n",
    "file_path = '../datasets/nippon_df.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcafe1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497ddd8",
   "metadata": {},
   "source": [
    "# Find missing files and update to the correct image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2648cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_image_list = []\n",
    "\n",
    "for i in list(product_df['Filename']):\n",
    "  full_image_filepath = os.path.join(nippon_img_folder,i)\n",
    "  if os.path.exists(full_image_filepath):\n",
    "    missing_image_list.append(os.path.join(nippon_img_folder,i))\n",
    "  else:\n",
    "    print(f\"Error finding image path: {full_image_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af5edc",
   "metadata": {},
   "source": [
    "# Moving old product image to archive when it is no longer in the CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71afe4a",
   "metadata": {},
   "source": [
    "When there are new updates to the catalogue, it will archive the images so that it will not be included in the recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "listdir = os.listdir(nippon_img_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_img_path = os.path.join(nippon_img_folder,\"archived\")\n",
    "if not os.path.exists(archive_img_path):\n",
    "    os.makedirs(archive_img_path)  # Create the archive folder if it doesn't exist\n",
    "\n",
    "# Iterate over all files in the image folder\n",
    "for image in listdir:\n",
    "    if os.path.isfile(image):\n",
    "        # Extract the name or identifier from the image filename\n",
    "        image_name = os.path.basename(image)  # Adjust this according to your filename structure\n",
    "\n",
    "        # Check if this image_name exists in the DataFrame\n",
    "        if not any(product_df['Filename'].astype(str).str.contains(image_name)):\n",
    "            # Move the file to the archive folder\n",
    "            try:\n",
    "                shutil.move(os.path.join(nippon_img_folder, image), os.path.join(archive_img_path, image))\n",
    "                print(f'Image moved to archived: {os.path.join(nippon_img_folder, image)}')\n",
    "            except:\n",
    "                print(f'Error: Image not found: {os.path.join(nippon_img_folder, image)}')\n",
    "\n",
    "            print(image_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2759075a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8657adf",
   "metadata": {},
   "source": [
    "### Next Notebook: [1.5 Consolidate All Product Database](1.5_consolidate_product_database.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
